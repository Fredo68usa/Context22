import xgboost as xgb
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_squared_error
from icecream import ic
from elasticsearch import Elasticsearch, helpers
import sys
import json
from sklearn.model_selection import TimeSeriesSplit

class xgboost:



  # --- Constructor ------
  def __init__(self,param_json):

    # self.process = psutil.Process(os.getpid())
    # self.timeSeries = str(sys.argv[1])
    self.timeSeries = 'power_consumption_days'

    # --- Getting parameters from Param File
    with open(param_json) as f:
         self.param_data = json.load(f)

    self.path = self.param_data["path"]
    self.pathlength=len(self.path)
    self.pathProcessed = self.param_data["pathProcessed"]
    self.confidentialityPolicyRule = self.param_data["confidentialityPolicyRule"]
    self.datafileNotinserted=self.pathProcessed + "NotInserted"

    self.esServer = self.param_data["ESServer"]
    self.esUser = self.param_data["ESUser"]
    self.esPwd = self.param_data["ESPwd"]

    self.ExcessiveExtractionCheck = self.param_data["ExcessiveExtractionCheck"]

    self.es = Elasticsearch([self.esServer], http_auth=(self.esUser, self.esPwd))

    self.index = self.param_data["index"]
    self.sqlite = self.param_data["sqlite"]
    print('Number of arguments:', len(sys.argv), 'arguments.')
    print('Argument List:', str(sys.argv))

    return(None)
      
  def cross_valid(self):
    # --- n_splits = how many times the training-testing split will be performed
    tss = TimeSeriesSplit(n_splits=2, test_size=365*1, gap=7)
    ic(type(tss))
    self.df_ts = self.df_ts.sort_index()

    fold = 0
    preds = []
    scores = []
    ic(tss.split(self.df_ts))

    tss = TimeSeriesSplit(n_splits=2, test_size=365*1, gap=7)
    ic(type(tss))
    # self.df_ts = self.df_ts.sort_index()


    reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree', n_estimators=1000, early_stopping_rounds=50, objective='reg:linear', max_depth=3, learning_rate=0.01)
    # reg.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)


  # --- Read the TS

  # def getTS(self):
  def getTS(self):
        print ("Getting the Time Series")
        # body={"query" : { "bool" : { "must" : [{"match": {"HashHash" : self.SQLHash}} ,{ "match": {"DayOfWeek" : "Thursday"} } ] }} , "size" : 1000}
        # body={"query": {"match_all": {}}, "size" : 10000}
        fields_to_retrieve = ['timestamp','Global_active_power']
        body={"query": {"match_all": {}}, "size" : 10000, "_source": fields_to_retrieve}
        ts_ready_tmp = self.es.search(index=self.timeSeries, body=body)
        # ts_ready_tmp = self.es.search(index='power_consumption_days', body=body)
        # data = (ts_ready_tmp['hits']['hits'])

        # data = pd.DataFrame(ts_ready_tmp['hits']['hits'])
        data = ts_ready_tmp['hits']['hits']
        data = pd.DataFrame.from_dict(ts_ready_tmp['hits']['hits'])

        # ic(type(data))
        # ic(len(data))

        list_ts = data['_source'].tolist()
        ic(list_ts)
        self.df_ts = pd.DataFrame.from_dict(list_ts)
        self.df_ts['timestamp'] = pd.to_datetime(self.df_ts['timestamp'])
        ic(self.df_ts)



  def mainProcess(self):
    print ("Starting xgboost")
    # ---- Get the Time Series
    self.getTS()

    # self.trainTS()

    # self.create_features()

    # self.add_lags()

    self.cross_valid()


